{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class_weights = np.array([0,0.5,1,3,3.2,23.5,2.5,163.2,23.5])\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "       class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])\n",
    "       return K.sum(class_loglosses * K.constant(class_weights))\n",
    "\n",
    "def Unet(n_classes=9, im_sz=patch_size, n_channels=4,droprate=0.25):\n",
    "  \n",
    "    inputs = Input((im_sz, im_sz, n_channels))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(droprate)(pool1)\n",
    "\n",
    "    \n",
    "    pool1 = BatchNormalization()(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(droprate)(pool2)\n",
    "\n",
    "    \n",
    "    pool2 = BatchNormalization()(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(droprate)(pool3)\n",
    "\n",
    "    \n",
    "    conv4 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4), conv3])\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = Dropout(droprate)(conv6)\n",
    "\n",
    "    \n",
    "    up7 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv6), conv2])\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = Dropout(droprate)(conv7)\n",
    "\n",
    "    \n",
    "    up8 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv7), conv1])\n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv9 = Conv2D(9, (1, 1), activation='softmax')(conv8)\n",
    "    \n",
    "    model=Model(inputs=[inputs],outputs=[conv9])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating generator class to handle large input data easily\n",
    "\n",
    "from keras.utils import Sequence\n",
    "\n",
    "class Generator(Sequence):\n",
    "  \n",
    "  \n",
    "  def __init__(self,X,Y,batch):\n",
    "    self.x=X\n",
    "    self.y=Y\n",
    "    self.batch=batch\n",
    "    self.cnt=0\n",
    "    \n",
    "  def __len__(self):\n",
    "    return int(np.floor(np.array(self.x).shape[0]) / self.batch)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self,index):\n",
    "    path_x=self.x[index*self.batch:(index+1)*self.batch]                            #list contains paths (number=batch size) of the input patches \n",
    "    path_y=self.y[index*(self.batch):(index+1)*self.batch]                          #list contains paths of the corresponding gt patches \n",
    "    \n",
    "    X=[]\n",
    "    Y=[]\n",
    "    \n",
    "    for x_path,y_path in zip(path_x,path_y):\n",
    "      temp_x=np.load(x_path)                                                        #loading input data from given paths\n",
    "      temp_y=np.load(y_path)\n",
    "      #temp_mask=get_mask(temp_x,temp_y)\n",
    "      self.cnt=self.cnt+1\n",
    "      X.append(temp_x)            \n",
    "      Y.append(temp_y) \n",
    "    \n",
    "    X=np.array(X)\n",
    "    Y=np.array(Y)\n",
    "      \n",
    "    return X,Y                                                                       #passing the required list of input and gt patches                                                               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_patch_paths=[\"./Image_patch_new/img_patch\"+str(i)+\".npy\" for i in range(0,datasize)]                #storing patch paths to be passed ot the generator\n",
    "Y_patch_paths=[\"./mask_patch_new/mask_patch\"+str(i)+\".npy\" for i in range(0,datasize)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting data into training and validation set \n",
    "\n",
    "X_path_train = X_patch_paths[:train_data]\n",
    "Y_path_train = Y_patch_paths[:train_data]\n",
    "X_path_val = X_patch_paths[train_data:]\n",
    "Y_path_val = Y_patch_paths[train_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################## defining the model ##################################\n",
    "\n",
    "model=Unet(n_classes=9, im_sz=patch_size, n_channels=4,droprate=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.summary()\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')\n",
    "#print(plot_model(model, to_file='model.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",loss=weighted_binary_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining required generators\n",
    "\n",
    "training_generator = Generator(X_path_train ,Y_path_train ,6)\n",
    "val_generator = Generator(X_path_val ,Y_path_val ,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################## Training model over the training data ##########################################\n",
    "\n",
    "\n",
    "model.fit_generator(generator=training_generator, \n",
    "                    use_multiprocessing=True ,\n",
    "                    validation_data=val_generator,\n",
    "                    workers=6,\n",
    "                    callbacks= [model_checkpoint],\n",
    "                    epochs=20)\n",
    "\n",
    "print(\"completed fitting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"saving model\")\n",
    "\n",
    "model.save(\"./my_model_320_4.h5\")\n",
    "\n",
    "\n",
    "print(\"model saved\")\n",
    "########################## Training part finished  #############################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
